# day_1

[toc]



### 深度学习的概念

* 机器学习的分支，以神经网络作为基础，对数据的特征进行学习

### 和机器学习的区别

* 深度学习不需要手动的进行特征工程
* 深度学习需要的数据数量多，需要的计算机性能强

### 应用场景

1. 图像识别
   1. 物体识别
   2. 场景识别
   3. 人脸检测跟踪
   4. 人脸身份识别
2. 自然语言处理技术
   1. 机器翻译
   2. 文本识别
   3. 聊天对话
3. 语音技术
   1. 语音识别

### 常见框架

TensorFlow，Caffe2，Keras，Theano，PyTorch等等。

### 神经网络

1. 概念

   模仿生物的神经系统模型，能够对数据的特征进行学习

2. 神经元

   1. 神经网络中最小的单元，不同的神经元组合能够得到神经网络
   2. 结构：$t = f(wx+b)$
   3. 内积：点积，向量的乘法得到一个标量，再通过整流单元（激活函数）统一输出

### 单层神经网络

实际应用中很少见

### 两层神经网络

1. **感知机**

   感知机由**两层**神经网络组成，**输入层**接收外界输入信号后传递给**输出层**，输出层是M-P神经元（只有一个神经元）

   ![image5ad9b70353958173.png](https://file.moetu.org/images/2020/02/03/image5ad9b70353958173.png)

   **感知机的作用：**

   把一个n维向量空间用一个超平面分割成两部分，给定一个输入向量，超平面可以判断出其位于平面的那一面，得到输入的是正类还是反类，**对应待二维空间就是一条之间把一个平面分为两个部分**。进行二分类，与逻辑回归的区别是有一个激活函数。

### 多层神经网络

1. 输入层
2. 隐藏层
3. 输出层
4. 注意：
   1. 在神经网络中，每一层的神经元之间是没有连接的。
   2. 全连接层：这一层的每一个神经元都与上一层的每一个神经元之间都有连接，称当前层为全连接层，他们的计算方式如下使用矩阵的乘法

![imageb40a229950a58491.png](https://file.moetu.org/images/2020/02/03/imageb40a229950a58491.png)

### 激活函数

把原来的数据进行一个变化。在不使用激活函数是，模型有再多的层也不能增加模型的表现力。

* 为什么要使用非线性的激活函数：
  * 线性神经网络多层和两层没有区别
  * 使用非线性激活函数能增加模型的非线性分割能力
* 为什么使用简单的激活函数（ReLU）：
  * 因为简单的激活函数便于求导
  * sigmoid函数在取值很大或很小时导数会非常小导致参数的更新速度很慢 
* 还可以提高模型的鲁棒性
* 缓解梯度消失问题
* 加速模型收敛速度

### PyTorch的使用

1. 张量Tensor

   1. 0阶张量：常数，1
   2. 1阶张量：向量，[1, 2, 3]
   3. 2阶张量：矩阵，[[1, 2], [3, 4]]

2. 张量的创建

   1. `torch.tensor(list/array)`
   2. `torch.ones/zeros/empty[2, 3]`
   3. `torch.rand([3, 4])` 随机取值的范围是0~1
   4. `torch.randint(low, high, size=[a,b])` 在low到high的范围之间随机取整数，形状为a，b的矩阵
   5. `torch.randn([a, b])` 随机取正态分布，平均为0，标准差为1

3. 张量相关的属性和方法

   1. tensor中只有一个元素的时候获取其中的数据

      * `tensor.item()`

   2. tensor转化为`ndarry`

      * `tensor.numpy()`

   3. 获取tensor的形状

      * `tensor.shape()` 可以在其中传参，传参表示获取的是第几个维度的数据

   4. tensor的变形和装置

      * `tensor.view(a,b,c,...)` 将原张量改变为...

      * `tensor.transpose(a,b)` 指定转置的维度，有时后面的维度会写上-1，这是剩下的维度让计算机自己去计算的意思

   5. numpy中的切片索引依然适用

   6. 获取tensor中的最大值

      * `tensor.max()`
      * `tensor.max(dim=-1)`，会返回最大值，与最大值在行中的位置

   7. 获取tensor的数据类型

      * `tensor.dtype`

   8. 创建数据是指定类型与类型的修改

      * `torch.ones([2,3], dtype=float64)`
      * `tensor.type(torch.int64)`

   9. new方法可以简单替换tensor中的所有数据

   10. tensor的计算，所有带下划线的方法就是直接对原数据进行修改

       * tensor + tensor 对应位置相加，如果形状相同进行广播
       * tensor + 数字 tensor中的每一个数字都加这个数字
       * 带下划线的计算，直接对原数据进行修改

### CUDA类型的tensor

`torch.cuda`这个模块增加了对CUDA tensor的支持，能够在cpu和gpu上使用相同的方法操作tensor

通过`.to`方法能够把一个tensor转移到另一个设备（比如从cpu转移到gpu）

CUDA tensor的创建和转换：

* `device = torch.device("cuda" if torch.cuda.is_available() else "cpu")`

* ![image3eaa54fa9719dab4.png](https://file.moetu.org/images/2020/02/04/image3eaa54fa9719dab4.png)

  